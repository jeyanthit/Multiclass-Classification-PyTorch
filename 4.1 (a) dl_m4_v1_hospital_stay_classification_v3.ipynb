{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the length of hospital stay for a patient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('hospital_stay_training_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for null values in our dataset and verify the type of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 318438 entries, 0 to 318437\n",
      "Data columns (total 18 columns):\n",
      " #   Column                             Non-Null Count   Dtype  \n",
      "---  ------                             --------------   -----  \n",
      " 0   case_id                            318438 non-null  int64  \n",
      " 1   Hospital_code                      318438 non-null  int64  \n",
      " 2   Hospital_type_code                 318438 non-null  object \n",
      " 3   City_Code_Hospital                 318438 non-null  int64  \n",
      " 4   Hospital_region_code               318438 non-null  object \n",
      " 5   Available Extra Rooms in Hospital  318438 non-null  int64  \n",
      " 6   Department                         318438 non-null  object \n",
      " 7   Ward_Type                          318438 non-null  object \n",
      " 8   Ward_Facility_Code                 318438 non-null  object \n",
      " 9   Bed Grade                          318325 non-null  float64\n",
      " 10  patientid                          318438 non-null  int64  \n",
      " 11  City_Code_Patient                  313906 non-null  float64\n",
      " 12  Type of Admission                  318438 non-null  object \n",
      " 13  Severity of Illness                318438 non-null  object \n",
      " 14  Visitors with Patient              318438 non-null  int64  \n",
      " 15  Age                                318438 non-null  object \n",
      " 16  Admission_Deposit                  318438 non-null  float64\n",
      " 17  Stay                               318438 non-null  object \n",
      "dtypes: float64(3), int64(6), object(9)\n",
      "memory usage: 43.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NaNs: ['Bed Grade', 'City_Code_Patient']\n"
     ]
    }
   ],
   "source": [
    "# Find columns with NaN values\n",
    "columns_with_nans = df.columns[df.isna().any()].tolist()\n",
    "\n",
    "# Print the names of columns with NaNs\n",
    "print(\"Columns with NaNs:\", columns_with_nans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop rows in the dataset with null values in any of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case_id                              313793\n",
       "Hospital_code                        313793\n",
       "Hospital_type_code                   313793\n",
       "City_Code_Hospital                   313793\n",
       "Hospital_region_code                 313793\n",
       "Available Extra Rooms in Hospital    313793\n",
       "Department                           313793\n",
       "Ward_Type                            313793\n",
       "Ward_Facility_Code                   313793\n",
       "Bed Grade                            313793\n",
       "patientid                            313793\n",
       "City_Code_Patient                    313793\n",
       "Type of Admission                    313793\n",
       "Severity of Illness                  313793\n",
       "Visitors with Patient                313793\n",
       "Age                                  313793\n",
       "Admission_Deposit                    313793\n",
       "Stay                                 313793\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution (%):\n",
      " Stay\n",
      "21-30                 27.507306\n",
      "11-20                 24.568744\n",
      "31-40                 17.308225\n",
      "51-60                 10.982718\n",
      "0-10                   7.409343\n",
      "41-50                  3.677902\n",
      "71-80                  3.217408\n",
      "More than 100 Days     2.086726\n",
      "81-90                  1.517242\n",
      "91-100                 0.864583\n",
      "61-70                  0.859802\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# The column \"Stay\" is what we have to predict. Check the distribution of the 'Stay' column\n",
    "class_distribution = df['Stay'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Class Distribution (%):\\n\", class_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the categorical and numerical columns and transform them in preparation for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encode categorical variables and normalize numerical variables\n",
    "categorical_columns = ['Hospital_code', 'Hospital_type_code', 'City_Code_Hospital', 'Hospital_region_code', 'Department', 'Ward_Type', 'Ward_Facility_Code', 'Bed Grade', 'City_Code_Patient','Type of Admission', 'Severity of Illness', 'Age']\n",
    "numerical_columns = ['Available Extra Rooms in Hospital', 'Visitors with Patient', 'Admission_Deposit']\n",
    "\n",
    "# Encoding and Normalizing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_columns),\n",
    "        ('cat', OneHotEncoder(), categorical_columns)\n",
    "        #('cat', OrdinalEncoder(handle_unknown='use_encoded_value'), categorical_columns)\n",
    "\n",
    "    ])\n",
    "\n",
    "# Preparing target\n",
    "label_encoder = LabelEncoder()\n",
    "df['Stay'] = label_encoder.fit_transform(df['Stay'])\n",
    "\n",
    "# Splitting the dataset\n",
    "X = df.drop(['patientid','Stay'], axis=1)\n",
    "y = df['Stay']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply preprocessing: create a model based on the dataset and then transform the dataset based on the created model\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.toarray().astype(np.float32))\n",
    "y_train_tensor = torch.tensor(y_train.values.astype(np.int64))\n",
    "X_test_tensor = torch.tensor(X_test.toarray().astype(np.float32))\n",
    "y_test_tensor = torch.tensor(y_test.values.astype(np.int64))\n",
    "\n",
    "# Prepare DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define our neural network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HospitalStayNet(nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(HospitalStayNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_features, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Determine the number of features from the column count of the dataset\n",
    "num_features = X_train.shape[1]\n",
    "num_classes = 11  # As mentioned, there are 11 classes\n",
    "# Use GPU, if it is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "model = HospitalStayNet(num_features, num_classes).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the function that calculates our trained model's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(loader):\n",
    "    model.eval()  # Set the model to evaluation mode. \n",
    "\n",
    "    correct = 0  # the number of correct predictions.\n",
    "    total = 0  # the total number of predictions.\n",
    "\n",
    "    with torch.no_grad():  # Disable the gradient calculation to save memory and speed up the process since gradients are not needed for evaluation.\n",
    "        # Iterate over the data loader, which provides batches of inputs and their corresponding targets.\n",
    "        for inputs, targets in loader:  \n",
    "            inputs, targets = inputs.to(device), targets.to(device)  \n",
    "\n",
    "            outputs = model(inputs)  # Compute the model's outputs for the given inputs.\n",
    "\n",
    "            # Find the predicted class with the highest score for each input. \n",
    "            # The `torch.max` function returns both the maximum values and their indices (the predicted classes)\n",
    "            _, predicted = torch.max(outputs.data, 1)  \n",
    "            # targets.size(0) gives the number of targets in the batch.\n",
    "            total += targets.size(0)  \n",
    "            # Calculate the number of correct predictions in the batch by comparing predicted with targets, summing the true predictions, and adding this sum to the correct counter.\n",
    "            correct += (predicted == targets).sum().item()  \n",
    "\n",
    "    return 100 * correct / total  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the loss function and the optimzer to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.4275, Train Accuracy: 42.32%, Test Accuracy: 42.63%\n",
      "Epoch 2, Loss: 1.3981, Train Accuracy: 42.72%, Test Accuracy: 42.68%\n",
      "Epoch 3, Loss: 1.3693, Train Accuracy: 43.10%, Test Accuracy: 42.98%\n",
      "Epoch 4, Loss: 1.3418, Train Accuracy: 43.15%, Test Accuracy: 42.97%\n",
      "Epoch 5, Loss: 1.5585, Train Accuracy: 43.10%, Test Accuracy: 42.84%\n",
      "Epoch 6, Loss: 1.5117, Train Accuracy: 43.39%, Test Accuracy: 42.96%\n",
      "Epoch 7, Loss: 1.4212, Train Accuracy: 43.49%, Test Accuracy: 43.11%\n",
      "Epoch 8, Loss: 1.8734, Train Accuracy: 43.50%, Test Accuracy: 43.19%\n",
      "Epoch 9, Loss: 1.8632, Train Accuracy: 43.59%, Test Accuracy: 42.96%\n",
      "Epoch 10, Loss: 1.4188, Train Accuracy: 43.69%, Test Accuracy: 42.79%\n",
      "Epoch 11, Loss: 1.3809, Train Accuracy: 43.82%, Test Accuracy: 42.90%\n",
      "Epoch 12, Loss: 1.4405, Train Accuracy: 43.64%, Test Accuracy: 42.83%\n",
      "Epoch 13, Loss: 1.6338, Train Accuracy: 44.03%, Test Accuracy: 42.81%\n",
      "Epoch 14, Loss: 1.5955, Train Accuracy: 43.95%, Test Accuracy: 42.67%\n",
      "Epoch 15, Loss: 1.2276, Train Accuracy: 44.19%, Test Accuracy: 42.77%\n",
      "Epoch 16, Loss: 1.5178, Train Accuracy: 44.25%, Test Accuracy: 42.93%\n",
      "Epoch 17, Loss: 1.4150, Train Accuracy: 44.18%, Test Accuracy: 42.70%\n",
      "Epoch 18, Loss: 1.2069, Train Accuracy: 44.33%, Test Accuracy: 42.65%\n",
      "Epoch 19, Loss: 1.1609, Train Accuracy: 44.30%, Test Accuracy: 42.68%\n",
      "Epoch 20, Loss: 1.4211, Train Accuracy: 44.40%, Test Accuracy: 42.44%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()       # Set the model to training mode. \n",
    "    # Iterate over the data loader, which provides batches of inputs and their corresponding targets.\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad() # initialize the gradients for this batch of data\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets) # calculate the losses\n",
    "        loss.backward()  # compute the gradients based on the loss values\n",
    "        optimizer.step() # update the weights and biases based on the loss values\n",
    "    \n",
    "    train_accuracy = calculate_accuracy(train_loader)\n",
    "    test_accuracy = calculate_accuracy(test_loader)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}, Train Accuracy: {train_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The difference between training and test accuracy is 1.96\n",
    "##### Epoch 20, Loss: 1.4211, Train Accuracy: 44.40%, Test Accuracy: 42.44%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'hospital_stay_model.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a newer model with more layers and nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HospitalStayNet256(nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(HospitalStayNet256, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_features, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.fc5 = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "model = HospitalStayNet256(num_features, num_classes).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.7144, Train Accuracy: 42.5524%, Test Accuracy: 42.6552%\n",
      "Epoch 2, Loss: 1.2402, Train Accuracy: 42.5755%, Test Accuracy: 42.7333%\n",
      "Epoch 3, Loss: 1.7224, Train Accuracy: 43.0081%, Test Accuracy: 43.0424%\n",
      "Epoch 4, Loss: 1.9438, Train Accuracy: 42.9468%, Test Accuracy: 42.7381%\n",
      "Epoch 5, Loss: 1.5798, Train Accuracy: 43.2157%, Test Accuracy: 43.0042%\n",
      "Epoch 6, Loss: 1.5262, Train Accuracy: 43.3858%, Test Accuracy: 42.7859%\n",
      "Epoch 7, Loss: 1.3699, Train Accuracy: 43.4344%, Test Accuracy: 42.6138%\n",
      "Epoch 8, Loss: 1.6594, Train Accuracy: 43.8857%, Test Accuracy: 43.0217%\n",
      "Epoch 9, Loss: 1.2425, Train Accuracy: 43.9717%, Test Accuracy: 42.9006%\n",
      "Epoch 10, Loss: 1.6484, Train Accuracy: 44.1629%, Test Accuracy: 43.0090%\n",
      "Epoch 11, Loss: 1.1459, Train Accuracy: 44.2319%, Test Accuracy: 42.7731%\n",
      "Epoch 12, Loss: 1.7826, Train Accuracy: 44.5346%, Test Accuracy: 42.5533%\n",
      "Epoch 13, Loss: 1.7301, Train Accuracy: 45.1090%, Test Accuracy: 42.7158%\n",
      "Epoch 14, Loss: 1.6124, Train Accuracy: 44.9724%, Test Accuracy: 42.5453%\n",
      "Epoch 15, Loss: 1.4186, Train Accuracy: 45.4711%, Test Accuracy: 42.4194%\n",
      "Epoch 16, Loss: 1.2612, Train Accuracy: 45.7564%, Test Accuracy: 42.5310%\n",
      "Epoch 17, Loss: 1.6371, Train Accuracy: 46.0248%, Test Accuracy: 42.0880%\n",
      "Epoch 18, Loss: 1.5139, Train Accuracy: 46.3746%, Test Accuracy: 42.0370%\n",
      "Epoch 19, Loss: 1.2457, Train Accuracy: 46.4427%, Test Accuracy: 41.8362%\n",
      "Epoch 20, Loss: 1.3692, Train Accuracy: 46.4993%, Test Accuracy: 41.6036%\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_accuracy = calculate_accuracy(train_loader)\n",
    "    test_accuracy = calculate_accuracy(test_loader)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}, Train Accuracy: {train_accuracy:.4f}%, Test Accuracy: {test_accuracy:.4f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that the more complex model achieves better training accuracy, but the difference the training and test accuracies has increased\n",
    "##### Epoch 20, Loss: 1.3692, Train Accuracy: 46.4993%, Test Accuracy: 41.6036%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define another model with dropout layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HospitalStayNetWithDropout(nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(HospitalStayNetWithDropout, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_features, 128)\n",
    "        self.dropout1 = nn.Dropout(0.5)  # Dropout layer with 50% probability\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        #self.dropout2 = nn.Dropout(0.5)  # Another Dropout layer\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = HospitalStayNetWithDropout(num_features, num_classes).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model with the dropout layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.4371, Train Accuracy: 41.77%, Test Accuracy: 42.19%\n",
      "Epoch 2, Loss: 1.5844, Train Accuracy: 42.20%, Test Accuracy: 42.49%\n",
      "Epoch 3, Loss: 1.9316, Train Accuracy: 42.41%, Test Accuracy: 42.67%\n",
      "Epoch 4, Loss: 1.5281, Train Accuracy: 42.65%, Test Accuracy: 42.91%\n",
      "Epoch 5, Loss: 1.6003, Train Accuracy: 42.65%, Test Accuracy: 42.88%\n",
      "Epoch 6, Loss: 1.5556, Train Accuracy: 42.86%, Test Accuracy: 42.95%\n",
      "Epoch 7, Loss: 1.2876, Train Accuracy: 42.88%, Test Accuracy: 42.98%\n",
      "Epoch 8, Loss: 1.4784, Train Accuracy: 42.75%, Test Accuracy: 42.77%\n",
      "Epoch 9, Loss: 1.6877, Train Accuracy: 42.94%, Test Accuracy: 43.01%\n",
      "Epoch 10, Loss: 1.6729, Train Accuracy: 42.88%, Test Accuracy: 42.97%\n",
      "Epoch 11, Loss: 1.5647, Train Accuracy: 42.80%, Test Accuracy: 42.99%\n",
      "Epoch 12, Loss: 1.6370, Train Accuracy: 43.02%, Test Accuracy: 43.07%\n",
      "Epoch 13, Loss: 1.6155, Train Accuracy: 42.93%, Test Accuracy: 42.97%\n",
      "Epoch 14, Loss: 1.2246, Train Accuracy: 43.17%, Test Accuracy: 43.10%\n",
      "Epoch 15, Loss: 1.4217, Train Accuracy: 43.13%, Test Accuracy: 42.93%\n",
      "Epoch 16, Loss: 1.8566, Train Accuracy: 43.10%, Test Accuracy: 43.10%\n",
      "Epoch 17, Loss: 1.1886, Train Accuracy: 43.07%, Test Accuracy: 42.89%\n",
      "Epoch 18, Loss: 1.6005, Train Accuracy: 43.18%, Test Accuracy: 43.18%\n",
      "Epoch 19, Loss: 1.4324, Train Accuracy: 43.11%, Test Accuracy: 42.97%\n",
      "Epoch 20, Loss: 1.4657, Train Accuracy: 43.16%, Test Accuracy: 42.99%\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_accuracy = calculate_accuracy(train_loader)\n",
    "    test_accuracy = calculate_accuracy(test_loader)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}, Train Accuracy: {train_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that although the model with dropout layers has lesser training accuracy compare to the 5 layer model created earlier, its test accuracy is better and the difference between training and test accuracy is only 1.17\n",
    "##### Epoch 20, Loss: 1.4657, Train Accuracy: 43.16%, Test Accuracy: 42.99%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define another model with Batch Normalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HospitalStayNetWithBN(nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(HospitalStayNetWithBN, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_features, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = HospitalStayNetWithBN(num_features, num_classes).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model with batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.6159, Train Accuracy: 41.81%, Test Accuracy: 42.04%\n",
      "Epoch 2, Loss: 1.4692, Train Accuracy: 42.60%, Test Accuracy: 42.60%\n",
      "Epoch 3, Loss: 1.6270, Train Accuracy: 42.81%, Test Accuracy: 42.78%\n",
      "Epoch 4, Loss: 1.7667, Train Accuracy: 43.06%, Test Accuracy: 42.88%\n",
      "Epoch 5, Loss: 1.5386, Train Accuracy: 43.26%, Test Accuracy: 42.93%\n",
      "Epoch 6, Loss: 1.7066, Train Accuracy: 43.36%, Test Accuracy: 42.89%\n",
      "Epoch 7, Loss: 1.3127, Train Accuracy: 43.36%, Test Accuracy: 43.00%\n",
      "Epoch 8, Loss: 1.2792, Train Accuracy: 43.53%, Test Accuracy: 42.99%\n",
      "Epoch 9, Loss: 1.1534, Train Accuracy: 43.61%, Test Accuracy: 43.23%\n",
      "Epoch 10, Loss: 1.4579, Train Accuracy: 43.57%, Test Accuracy: 42.91%\n",
      "Epoch 11, Loss: 1.6568, Train Accuracy: 43.81%, Test Accuracy: 43.09%\n",
      "Epoch 12, Loss: 1.8723, Train Accuracy: 43.62%, Test Accuracy: 42.92%\n",
      "Epoch 13, Loss: 1.4746, Train Accuracy: 43.70%, Test Accuracy: 42.89%\n",
      "Epoch 14, Loss: 1.5525, Train Accuracy: 43.84%, Test Accuracy: 42.84%\n",
      "Epoch 15, Loss: 1.5841, Train Accuracy: 43.93%, Test Accuracy: 42.97%\n",
      "Epoch 16, Loss: 1.5146, Train Accuracy: 44.04%, Test Accuracy: 42.90%\n",
      "Epoch 17, Loss: 1.6085, Train Accuracy: 43.94%, Test Accuracy: 42.73%\n",
      "Epoch 18, Loss: 1.2596, Train Accuracy: 44.10%, Test Accuracy: 42.95%\n",
      "Epoch 19, Loss: 1.4945, Train Accuracy: 44.08%, Test Accuracy: 42.93%\n",
      "Epoch 20, Loss: 1.4538, Train Accuracy: 44.14%, Test Accuracy: 42.70%\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_accuracy = calculate_accuracy(train_loader)\n",
    "    test_accuracy = calculate_accuracy(test_loader)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}, Train Accuracy: {train_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Since our problem and thus the model is not highly complex, we do not really need batch normalization in this case. So the performance with and without batch normalization is similar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
